{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuMagLIgb5emydC2K0a8Ue"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"Tb1KFg0d1dZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from abc import ABC, abstractmethod\n","from tqdm import tqdm"],"metadata":{"id":"rAm6j3DjLlaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load files used to train other models\n","x_train = pd.read_csv('/content/x_train.csv')\n","x_test = pd.read_csv('/content/x_test.csv')\n","\n","y_train = pd.read_csv('/content/y_train.csv')\n","y_test = pd.read_csv('/content/y_test.csv')"],"metadata":{"id":"AKBH5dHHMUUV","executionInfo":{"status":"ok","timestamp":1722606119856,"user_tz":-60,"elapsed":191,"user":{"displayName":"Selma Phillemon","userId":"17558809159617160842"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["class MCMC(ABC):\n","    @abstractmethod\n","    def __init__():\n","        raise NotImplemented(f\"{type(self).__name__}: init not implemented\")\n","\n","    @abstractmethod\n","    def sampler():\n","        raise NotImplemented(f\"{type(self).__name__}: sampler not implemented\")\n"],"metadata":{"id":"H3Yok3929Smr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"U0pgqto798ca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MCMC_BNN(MCMC):\n","    def __init__(self, model, n_samples, n_burnin, x_data, y_data, x_test, y_test):\n","        self.n_samples = n_samples # number of MCMC samples\n","        self.n_burnin = n_burnin # number of burn-in samples\n","        self.x_data = x_data # (N x num_features)\n","        self.y_data = y_data # (N x 1)\n","        self.x_test = x_test # (Nt x num_features)\n","        self.y_test = y_test # (Nt x 1)\n","\n","        # MCMC sampler hyperparameters - defines how much variation you need in changes to theta, tau\n","        self.step_theta = 0.025;\n","        self.step_eta = 0.2; # note eta is used as tau in the sampler to consider log scale.\n","        # Hyperpriors\n","        self.sigma_squared = 25\n","        self.nu_1 = 0\n","        self.nu_2 = 0\n","\n","        # initisalise the linear model class\n","        self.model = model\n","        self.use_langevin_gradients = True\n","        self.sgd_depth = 1\n","        self.l_prob = 0.5 # likelihood prob\n","        self.theta_size = self.model.n_params # weights for each feature and a bias term\n","\n","        # store output\n","        self.pos_theta = None\n","        self.pos_tau = None\n","        self.pos_eta = None\n","        self.rmse_data = None\n","\n","        # functions defined above - this is poor practice, but done for readability\n","        # and clarity\n","        if self.model.data_case == 'regression':\n","            self.likelihood_function = self.regression_likelihood_function\n","            self.prior = self.regression_prior\n","        elif self.model.data_case == 'classification':\n","            self.likelihood_function = self.classification_likelihood_function\n","            self.prior = self.classification_prior\n","        else:\n","            raise ValueError('data_case must be regression or classification')"],"metadata":{"id":"Yn8ueF-y9Yhz"},"execution_count":null,"outputs":[]}]}